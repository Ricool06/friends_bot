{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://fangj.github.io/friends/'\n",
    "links = List[str]\n",
    "\n",
    "with requests.get(base_url) as response:\n",
    "    html = BeautifulSoup(response.text)\n",
    "    links = [a['href'] for a in html.find_all('a')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_script(i: int, path: str) -> str:\n",
    "    with requests.get(base_url + path) as page_res:\n",
    "        page_html = BeautifulSoup(page_res.text)\n",
    "    \n",
    "    try:\n",
    "        first_scene_annotation = page_html.find(text=re.compile('Scene:'))\n",
    "        after = first_scene_annotation.parent.find_next_siblings()\n",
    "\n",
    "        return '\\n'.join([first_scene_annotation] + [el.text for el in after])\n",
    "    except:\n",
    "        raise Exception('Loop failed on iteration: %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_friends_script = [extract_script(i, link) for i, link in enumerate(links) if i not in [26, 34]]\n",
    "# Episode 26 & 34 don't follow the pattern of transcription seen in other episode scripts.\n",
    "# They lack the first '[Scene: ...]' stage direction\n",
    "# Recommend a PR to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_friends_script = '\\n'.join(entire_friends_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_friends_script[:248]"
   ]
  },
  {
   "source": [
    "## Ingest is now done.\n",
    "The `entire_friends_script` variable holds the concatenated scripts for all the Friends episodes\n",
    "\n",
    "# You now need to run `run_modelling_on_gpt2.sh` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': \"PHOEBE: Ohh. Hi. How could you say no more?All: (wishes) Oh, okay, I'm back now.Joe: That sounds great! Ross: Thanks for making me feel welcome. Joey: (gives him a hug) Sorry, what were you just there for?Joey: I mean, I got my hair cut this morning, and I was waiting for my doctor's appointment, just as I had said I needed surgery.Joey: Really? What're you guys looking for anyway?Ross: ... (excitedly) How's it going today?All: So, I see that the doctors told me to use\"}]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline('text-generation', model='./test-clm')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('test-clm', local_files_only=True)\n",
    "# gpt2 = GPT2LMHeadModel.from_pretrained('test-clm', local_files_only=True)\n",
    "\n",
    "# token_ids = tokenizer('PHOEBE:', return_tensors='tf', return_token_type_ids=True)['input_ids']\n",
    "# token_ids\n",
    "# gpt2.generate(token_ids, max_length=140)\n",
    "model('PHOEBE:', max_length=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}