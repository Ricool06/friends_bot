{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is intended to:\n",
    "- Ingest the entire collected works of the TV show \"Friends\"\n",
    "- Preprocess the data by extracting text and concatenating into a single document\n",
    "- Train a Natural Language Processing model to generate similar works\n",
    "- Evaluate the model\n",
    "- Save the model so it may be used by a Twitter bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://fangj.github.io/friends/'\n",
    "links = List[str]\n",
    "\n",
    "with requests.get(base_url) as response:\n",
    "    html = BeautifulSoup(response.text)\n",
    "    links = [a['href'] for a in html.find_all('a')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_script(i: int, path: str) -> str:\n",
    "    with requests.get(base_url + path) as page_res:\n",
    "        page_html = BeautifulSoup(page_res.text)\n",
    "    \n",
    "    try:\n",
    "        first_scene_annotation = page_html.find(text=re.compile('Scene:'))\n",
    "        after = first_scene_annotation.parent.find_next_siblings()\n",
    "\n",
    "        return '\\n'.join([first_scene_annotation] + [el.text for el in after])\n",
    "    except:\n",
    "        raise Exception('Loop failed on iteration: %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_friends_script = [extract_script(i, link) for i, link in enumerate(links) if i not in [26, 34]]\n",
    "# Episode 26 & 34 don't follow the pattern of transcription seen in other episode scripts.\n",
    "# They lack the first '[Scene: ...]' stage direction\n",
    "# Recommend a PR to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_friends_script = '\\n'.join(entire_friends_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"[Scene: Central Perk, Chandler, Joey, Phoebe, and Monica are there.]\\nMonica: There's nothing to tell! He's just some guy\\nI work with!\\nJoey: C'mon, you're going out with the guy! There's\\ngotta be something wrong with him!\\nChandler: All right Joey, b\""
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "entire_friends_script[:248]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest is now done.\n",
    "The `entire_friends_script` variable holds the concatenated scripts for all the Friends episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(entire_friends_script))\n",
    "char_to_ind = {u:i for i, u in enumerate(vocab)}\n",
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_scripts = np.array([char_to_ind[c] for c in entire_friends_script])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = Dataset.from_tensor_slices(encoded_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desired_sequence_length = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(desired_sequence_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_target_pairs(sequence: str) -> (str, str):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('This is just some test text lo', 'his is just some test text lol')"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "create_input_target_pairs('This is just some test text lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_input_target_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "shuffle_buffer_size = 10000\n",
    "\n",
    "shuffled_dataset = dataset.shuffle(shuffle_buffer_size).batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset created\n",
    "Pairs of sequences shifted by 1 character have been shuffled into a dataset\n",
    "\n",
    "'Hello, I am Ricoo' -> 'ello, I am Ricool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dimension = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dimension,\n",
    "    batch_input_shape=[batch_size, None]))\n",
    "\n",
    "model.add(GRU(\n",
    "    1026,\n",
    "    return_sequences=True,\n",
    "    stateful=True,\n",
    "    recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(vocab_size))\n",
    "\n",
    "model.compile(optimizer='adam', loss=sparse_cat_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (128, None, 64)           6976      \n_________________________________________________________________\ngru (GRU)                    (128, None, 1026)         3361176   \n_________________________________________________________________\ndense (Dense)                (128, None, 109)          111943    \n=================================================================\nTotal params: 3,480,095\nTrainable params: 3,480,095\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model built\n",
    "The next bit is just to confirm the model shape and training is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(128, 140, 109)\n"
    }
   ],
   "source": [
    "for input_example, target_example in shuffled_dataset.take(1):\n",
    "    example_preds = model(input_example)\n",
    "\n",
    "    print(example_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.random import categorical\n",
    "from tensorflow import squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_preds_categories = categorical(example_preds[0], num_samples=1)\n",
    "example_preds_categories = squeeze(example_preds_categories, axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"1NFDymo!AppiC#?\\xa0%’<9É14>}?Dn—,&^wg46-y\\n!dqgVj}pbV.FQD<D&gGÉ>X�ZdTQ\\nGn`ECpç[E“8ME/#,wé-_t…un\\xa02b,r:=jtn|'}owkBG`(_l”VÉi—#–qI…!U�\\r;g3ZJH?gCCL$l\""
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "''.join(ind_to_char[example_preds_categories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape is correct\n",
    "Now to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/30\n170/170 [==============================] - 576s 3s/step - loss: 2.9734\nEpoch 2/30\n170/170 [==============================] - 559s 3s/step - loss: 2.0168\nEpoch 3/30\n170/170 [==============================] - 580s 3s/step - loss: 1.6797\nEpoch 4/30\n170/170 [==============================] - 452s 3s/step - loss: 1.4850\nEpoch 5/30\n170/170 [==============================] - 576s 3s/step - loss: 1.3712\nEpoch 6/30\n170/170 [==============================] - 483s 3s/step - loss: 1.2993\nEpoch 7/30\n170/170 [==============================] - 580s 3s/step - loss: 1.2496\nEpoch 8/30\n170/170 [==============================] - 584s 3s/step - loss: 1.2117\nEpoch 9/30\n170/170 [==============================] - 581s 3s/step - loss: 1.1813\nEpoch 10/30\n170/170 [==============================] - 583s 3s/step - loss: 1.1553\nEpoch 11/30\n170/170 [==============================] - 583s 3s/step - loss: 1.1325\nEpoch 12/30\n170/170 [==============================] - 567s 3s/step - loss: 1.1121\nEpoch 13/30\n170/170 [==============================] - 603s 4s/step - loss: 1.0935\nEpoch 14/30\n170/170 [==============================] - 600s 4s/step - loss: 1.0757\nEpoch 15/30\n170/170 [==============================] - 579s 3s/step - loss: 1.0587\nEpoch 16/30\n170/170 [==============================] - 580s 3s/step - loss: 1.0422\nEpoch 17/30\n170/170 [==============================] - 583s 3s/step - loss: 1.0265\nEpoch 18/30\n170/170 [==============================] - 581s 3s/step - loss: 1.0092\nEpoch 19/30\n170/170 [==============================] - 578s 3s/step - loss: 0.9943\nEpoch 20/30\n170/170 [==============================] - 577s 3s/step - loss: 0.9787\nEpoch 21/30\n170/170 [==============================] - 527s 3s/step - loss: 0.9639\nEpoch 22/30\n170/170 [==============================] - 462s 3s/step - loss: 0.9484\nEpoch 23/30\n170/170 [==============================] - 2348s 14s/step - loss: 0.9338\nEpoch 24/30\n170/170 [==============================] - 577s 3s/step - loss: 0.9189\nEpoch 25/30\n170/170 [==============================] - 523s 3s/step - loss: 0.9048\nEpoch 26/30\n170/170 [==============================] - 577s 3s/step - loss: 0.8927\nEpoch 27/30\n170/170 [==============================] - 453s 3s/step - loss: 0.8787\nEpoch 28/30\n170/170 [==============================] - 571s 3s/step - loss: 0.8676\nEpoch 29/30\n170/170 [==============================] - 579s 3s/step - loss: 0.8559\nEpoch 30/30\n170/170 [==============================] - 470s 3s/step - loss: 0.8445\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f9af3ba49a0>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "model.fit(shuffled_dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../func/resources/friends_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import TensorShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (1, None, 64)             6976      \n_________________________________________________________________\ngru_1 (GRU)                  (1, None, 1026)           3361176   \n_________________________________________________________________\ndense_1 (Dense)              (1, None, 109)            111943    \n=================================================================\nTotal params: 3,480,095\nTrainable params: 3,480,095\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "practice_model = Sequential()\n",
    "\n",
    "practice_model.add(Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dimension,\n",
    "    batch_input_shape=[1, None]))\n",
    "\n",
    "practice_model.add(GRU(\n",
    "    1026,\n",
    "    return_sequences=True,\n",
    "    stateful=True,\n",
    "    recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "practice_model.add(Dense(vocab_size))\n",
    "\n",
    "practice_model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "\n",
    "practice_model.load_weights('../../func/resources/friends_model.h5')\n",
    "\n",
    "practice_model.build(TensorShape([1, None]))\n",
    "\n",
    "practice_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import expand_dims\n",
    "\n",
    "def generate_text(this_model: Sequential, start_seed: str, num_chars=100, temp=1.0) -> str:\n",
    "  '''\n",
    "  model: Trained Model to Generate Text\n",
    "  start_seed: Intial Seed text in string form\n",
    "  gen_size: Number of characters to generate\n",
    "\n",
    "  Basic idea behind this function is to take in some seed text, format it so\n",
    "  that it is in the correct shape for our network, then loop the sequence as\n",
    "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "  time series problems.\n",
    "  '''\n",
    "\n",
    "  # Vecotrizing starting seed text\n",
    "  input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "  # Expand to match batch format shape\n",
    "  input_eval = expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty list to hold resulting generated text\n",
    "  text_generated = []\n",
    "\n",
    "  # Temperature effects randomness in our resulting text\n",
    "  # The term is derived from entropy/thermodynamics.\n",
    "  # The temperature is used to effect probability of next characters.\n",
    "  # Higher probability == lesss surprising/ more expected\n",
    "  # Lower temperature == more surprising / less expected\n",
    " \n",
    "  temperature = temp\n",
    "\n",
    "  # Here batch size == 1\n",
    "  this_model.reset_states()\n",
    "\n",
    "  for i in range(num_chars):\n",
    "\n",
    "      # Generate Predictions\n",
    "      predictions = this_model(input_eval)\n",
    "\n",
    "      # Remove the batch shape dimension\n",
    "      predictions = squeeze(predictions, 0)\n",
    "\n",
    "      # Use a cateogircal disitribution to select the next character\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the predicted charracter for the next input\n",
    "      input_eval = expand_dims([predicted_id], 0)\n",
    "\n",
    "      # Transform back to character letter\n",
    "      text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Phoebe)\nChandler: I’m not going to Paris.\nRachel: Oh my God! You gotta see. All right, all right. Look, why can't I tell you because he was caughtork on himself.)\nSarah: They gotta go... (Mrushink it's even Look.]\nRoss: (To Rachel) Me too.\n(to Barry Chandler and Monica point to uhm... \n"
    }
   ],
   "source": [
    "print(generate_text(practice_model, 'Phoebe', num_chars=280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../lambda/resources/vocab.json', 'w') as f:\n",
    "    json.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_model.save('../../func/resources/friends_practice_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('notebooks-4YGLAiTd-py3.8': venv)",
   "language": "python",
   "name": "python_defaultSpec_1595689185479"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}